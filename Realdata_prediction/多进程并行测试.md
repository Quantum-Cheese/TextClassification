#### 方案一  batch_predict.py

* 取出整批数据（根据定时任务实例启动时传的参：上次取到的最大id)

* 创建四个子进程，整批数据分成四个小 batch (不足四条不用分)，每个进程处理一个 batch 的数据

  * 每个进程内部：

  ​           整个batch数据直接批量分词（pandas.apply())

  ​           顺序遍历batch中的数据，每条数据先执行预测，再执行预测结果保存（直接插入数据库结果表）

  

  __历史数据速度测试__

  50条：  2min42s

  100 条：5min40s    （未改变子进程分配方式之前貌似更快？）

  800条：27min

  

#### 方案二  batch_predict_v2.py

- 取出整批数据（根据定时任务实例启动时传的参：上次取到的最大id)

- 创建四个子进程，整批数据分成四个小 batch (不足四条不用分)，每个进程处理一个 batch 的数据

  - 每个进程内部：

  ​           整个batch数据直接批量分词（pandas.apply())

  ​           整个batch数据直接批量预测 （pandas.apply())

  ​           顺序遍历batch中的数据，保存每条结果数据（直接插入数据库结果表）

   

  __历史数据速度测试__

  50 条： 3min01s 

  100 条数据：4min30s



#### 方案三（暂时弃用）

* 取出整批数据（根据定时任务实例启动时传的参：上次取到的最大id)

* 整批数据直接批量分词（pandas.apply())

* 并行预测：创建四个子进程，整批数据分四个小batch，每个batch整体批量预测（pandas.apply()），预测完再合并

* 并行保存：创建四个子进程，把存有预测结果的数据再分成四个小batch，每个batch顺序遍历保存入库

  



